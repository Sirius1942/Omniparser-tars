#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å›¾åƒå…ƒç´ åˆ†æå™¨ FastMCP æœåŠ¡å™¨
åŸºäº FastMCP æ¡†æ¶å®ç°å›¾ç‰‡åˆ†ææœåŠ¡
æ”¯æŒ GPU/CPU è‡ªåŠ¨é€‰æ‹©
"""

import os
import time
import base64
import io
import traceback
from typing import Dict, Any, Optional, List
from PIL import Image
import torch
from pathlib import Path

# FastMCP ç›¸å…³å¯¼å…¥ - å…¼å®¹æ€§ä¿®å¤ç‰ˆ
try:
    from fastmcp import FastMCP
    
    # å°è¯•å¤šç§æ–¹å¼å¯¼å…¥ Message å’Œ TextContent
    Message = None
    TextContent = None
    
    # æ–¹å¼1: ä» mcp.types å¯¼å…¥
    try:
        from mcp.types import Message, TextContent
    except ImportError:
        # æ–¹å¼2: ä» fastmcp ç›´æ¥å¯¼å…¥
        try:
            from fastmcp import Message, TextContent
        except ImportError:
            # æ–¹å¼3: ä» mcp å¯¼å…¥
            try:
                from mcp import Message, TextContent
            except ImportError:
                # æ–¹å¼4: ä½¿ç”¨åå¤‡ç±»å®šä¹‰
                class Message:
                    """æ¶ˆæ¯ç±» - å…¼å®¹ MCP åè®®"""
                    def __init__(self, role: str, content: list):
                        self.role = role
                        self.content = content
                
                class TextContent:
                    """æ–‡æœ¬å†…å®¹ç±» - å…¼å®¹ MCP åè®®"""
                    def __init__(self, text: str):
                        self.text = text
                        
                print("âš ï¸ ä½¿ç”¨å†…ç½®çš„ Message å’Œ TextContent ç±»")
    
except ImportError:
    print("âŒ FastMCP æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install fastmcp")
    print("   æˆ–è€…å°è¯•: pip install fastmcp mcp")
    exit(1)

# å¯¼å…¥å›¾åƒåˆ†æå™¨
from util.image_element_analyzer import ImageElementAnalyzer


# åˆ›å»º FastMCP æœåŠ¡å™¨å®ä¾‹
mcp = FastMCP(
    name="å›¾åƒå…ƒç´ åˆ†æå™¨",
    dependencies=["torch", "PIL", "pandas", "transformers", "ultralytics", "easyocr", "paddleocr"]
)

# å…¨å±€å˜é‡å­˜å‚¨åˆ†æå™¨å®ä¾‹
analyzer: Optional[ImageElementAnalyzer] = None
device_info: Dict[str, Any] = {}


def get_device_info() -> Dict[str, Any]:
    """è·å–è®¾å¤‡ä¿¡æ¯"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    info = {
        "device": device,
        "cuda_available": torch.cuda.is_available(),
    }
    
    if torch.cuda.is_available():
        info.update({
            "cuda_version": torch.version.cuda,
            "gpu_count": torch.cuda.device_count(),
            "current_gpu": torch.cuda.current_device(),
            "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else None,
            "gpu_memory": {
                "total": torch.cuda.get_device_properties(0).total_memory if torch.cuda.device_count() > 0 else 0,
                "allocated": torch.cuda.memory_allocated(0) if torch.cuda.device_count() > 0 else 0,
                "cached": torch.cuda.memory_reserved(0) if torch.cuda.device_count() > 0 else 0
            }
        })
    
    return info


def initialize_analyzer() -> bool:
    """åˆå§‹åŒ–åˆ†æå™¨"""
    global analyzer, device_info
    
    if analyzer is not None:
        return True
    
    try:
        device_info = get_device_info()
        print(f"ğŸš€ æ­£åœ¨åˆå§‹åŒ–å›¾åƒåˆ†æå™¨...")
        print(f"ğŸ–¥ï¸  è®¾å¤‡ä¿¡æ¯: {device_info['device']}")
        if device_info['cuda_available']:
            print(f"ğŸ® GPU: {device_info.get('gpu_name', 'Unknown')}")
        
        # æ£€æŸ¥æ¨¡å‹å’Œé…ç½®æ–‡ä»¶
        model_path = 'weights/icon_detect/model.pt'
        config_path = "config.json"
        
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
            
        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        analyzer = ImageElementAnalyzer(model_path, config_path)
        success = analyzer.initialize()
        
        if success:
            print("âœ… åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        else:
            print("âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–åˆ†æå™¨æ—¶å‡ºé”™: {e}")
        return False


@mcp.tool()
def analyze_image_file(
    image_path: str,
    box_threshold: float = 0.05,
    save_annotated: bool = False,
    output_dir: str = "./results"
) -> Dict[str, Any]:
    """
    åˆ†æå›¾åƒæ–‡ä»¶ä¸­çš„æ–‡æœ¬å’Œå›¾æ ‡å…ƒç´ 
    
    Args:
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        box_threshold: æ£€æµ‹æ¡†ç½®ä¿¡åº¦é˜ˆå€¼ (0.01-1.0)
        save_annotated: æ˜¯å¦ä¿å­˜æ ‡æ³¨åçš„å›¾åƒ
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        
    Returns:
        åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    if not initialize_analyzer():
        return {
            "success": False,
            "error": "åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥",
            "device_info": device_info
        }
    
    try:
        # å±•å¼€è·¯å¾„ä¸­çš„æ³¢æµªå·
        expanded_path = os.path.expanduser(image_path)
        
        if not os.path.exists(expanded_path):
            return {
                "success": False,
                "error": f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {expanded_path}"
            }
        
        print(f"ğŸ–¼ï¸  åˆ†æå›¾åƒ: {os.path.basename(expanded_path)}")
        
        # æ‰§è¡Œåˆ†æ
        result = analyzer.analyze_image(
            expanded_path,
            box_threshold=box_threshold,
            save_annotated=save_annotated,
            output_dir=output_dir,
            verbose=True
        )
        
        # æ·»åŠ è®¾å¤‡ä¿¡æ¯
        result["device_info"] = device_info
        
        return result
        
    except Exception as e:
        error_msg = f"åˆ†æå›¾åƒæ—¶å‡ºé”™: {str(e)}"
        print(f"âŒ {error_msg}")
        return {
            "success": False,
            "error": error_msg,
            "traceback": traceback.format_exc(),
            "device_info": device_info
        }


@mcp.tool()
def analyze_image_base64(
    image_base64: str,
    box_threshold: float = 0.05,
    save_annotated: bool = False,
    output_dir: str = "./results"
) -> Dict[str, Any]:
    """
    åˆ†æ Base64 ç¼–ç çš„å›¾åƒ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®
        box_threshold: æ£€æµ‹æ¡†ç½®ä¿¡åº¦é˜ˆå€¼ (0.01-1.0)
        save_annotated: æ˜¯å¦ä¿å­˜æ ‡æ³¨åçš„å›¾åƒ
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        
    Returns:
        åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    if not initialize_analyzer():
        return {
            "success": False,
            "error": "åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥",
            "device_info": device_info
        }
    
    try:
        # ç§»é™¤å¯èƒ½çš„å‰ç¼€
        if "," in image_base64:
            image_base64 = image_base64.split(",")[1]
        
        # è§£ç å›¾åƒ
        image_data = base64.b64decode(image_base64)
        image = Image.open(io.BytesIO(image_data))
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = f"temp_fastmcp_{int(time.time()*1000)}.png"
        image.save(temp_path)
        
        try:
            print(f"ğŸ–¼ï¸  åˆ†æ Base64 å›¾åƒ (å¤§å°: {image.size})")
            
            # æ‰§è¡Œåˆ†æ
            result = analyzer.analyze_image(
                temp_path,
                box_threshold=box_threshold,
                save_annotated=save_annotated,
                output_dir=output_dir,
                verbose=True
            )
            
            # æ·»åŠ è®¾å¤‡ä¿¡æ¯
            result["device_info"] = device_info
            
            return result
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)
                
    except Exception as e:
        error_msg = f"åˆ†æ Base64 å›¾åƒæ—¶å‡ºé”™: {str(e)}"
        print(f"âŒ {error_msg}")
        return {
            "success": False,
            "error": error_msg,
            "traceback": traceback.format_exc(),
            "device_info": device_info
        }


@mcp.tool()
def batch_analyze_images(
    image_paths: List[str],
    box_threshold: float = 0.05,
    save_annotated: bool = False,
    output_dir: str = "./results"
) -> Dict[str, Any]:
    """
    æ‰¹é‡åˆ†æå¤šä¸ªå›¾åƒæ–‡ä»¶
    
    Args:
        image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        box_threshold: æ£€æµ‹æ¡†ç½®ä¿¡åº¦é˜ˆå€¼ (0.01-1.0)
        save_annotated: æ˜¯å¦ä¿å­˜æ ‡æ³¨åçš„å›¾åƒ
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        
    Returns:
        åŒ…å«æ‰¹é‡åˆ†æç»“æœçš„å­—å…¸
    """
    # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    if not initialize_analyzer():
        return {
            "success": False,
            "error": "åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥",
            "device_info": device_info
        }
    
    try:
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡åˆ†æ {len(image_paths)} ä¸ªå›¾åƒ...")
        
        results = {}
        success_count = 0
        
        for i, image_path in enumerate(image_paths, 1):
            expanded_path = os.path.expanduser(image_path)
            print(f"\n[{i}/{len(image_paths)}] å¤„ç†: {os.path.basename(expanded_path)}")
            
            if not os.path.exists(expanded_path):
                results[image_path] = {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {expanded_path}"
                }
                continue
            
            try:
                result = analyzer.analyze_image(
                    expanded_path,
                    box_threshold=box_threshold,
                    save_annotated=save_annotated,
                    output_dir=output_dir,
                    verbose=False
                )
                
                results[image_path] = result
                
                if result.get("success", False):
                    success_count += 1
                    count = result.get("element_count", {})
                    print(f"âœ… å®Œæˆ - æ–‡æœ¬:{count.get('text', 0)} å›¾æ ‡:{count.get('icon', 0)}")
                else:
                    print(f"âŒ å¤±è´¥ - {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                error_msg = f"åˆ†æå¤±è´¥: {str(e)}"
                results[image_path] = {
                    "success": False,
                    "error": error_msg
                }
                print(f"âŒ å¤±è´¥ - {error_msg}")
        
        return {
            "success": True,
            "total_images": len(image_paths),
            "success_count": success_count,
            "failed_count": len(image_paths) - success_count,
            "results": results,
            "device_info": device_info
        }
        
    except Exception as e:
        error_msg = f"æ‰¹é‡åˆ†æå‡ºé”™: {str(e)}"
        print(f"âŒ {error_msg}")
        return {
            "success": False,
            "error": error_msg,
            "traceback": traceback.format_exc(),
            "device_info": device_info
        }


@mcp.tool()
def get_device_status() -> Dict[str, Any]:
    """
    è·å–å½“å‰è®¾å¤‡çŠ¶æ€ä¿¡æ¯
    
    Returns:
        åŒ…å«è®¾å¤‡ä¿¡æ¯çš„å­—å…¸
    """
    try:
        current_info = get_device_info()
        
        # å¦‚æœæœ‰ CUDAï¼Œæ›´æ–°å†…å­˜ä¿¡æ¯
        if current_info['cuda_available']:
            current_info['gpu_memory'] = {
                "total": torch.cuda.get_device_properties(0).total_memory,
                "allocated": torch.cuda.memory_allocated(0),
                "cached": torch.cuda.memory_reserved(0),
                "free": torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)
            }
        
        # æ£€æŸ¥åˆ†æå™¨çŠ¶æ€
        analyzer_status = {
            "initialized": analyzer is not None,
            "ready": analyzer is not None and analyzer._initialized if analyzer else False
        }
        
        return {
            "success": True,
            "device_info": current_info,
            "analyzer_status": analyzer_status,
            "timestamp": time.time()
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–è®¾å¤‡çŠ¶æ€å¤±è´¥: {str(e)}",
            "timestamp": time.time()
        }


@mcp.resource("image://recent/{filename}")
def get_recent_image_analysis(filename: str) -> str:
    """
    è·å–æœ€è¿‘åˆ†æçš„å›¾åƒç»“æœ
    
    Args:
        filename: å›¾åƒæ–‡ä»¶å
        
    Returns:
        å›¾åƒåˆ†æç»“æœçš„æ–‡æœ¬æè¿°
    """
    try:
        # åœ¨ç»“æœç›®å½•ä¸­æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
        results_dir = Path("./results")
        if not results_dir.exists():
            return f"ç»“æœç›®å½•ä¸å­˜åœ¨: {results_dir}"
        
        # æŸ¥æ‰¾å¯èƒ½çš„ç»“æœæ–‡ä»¶
        possible_files = list(results_dir.glob(f"*{filename}*"))
        
        if not possible_files:
            return f"æœªæ‰¾åˆ°ä¸ '{filename}' ç›¸å…³çš„åˆ†æç»“æœ"
        
        # è¿”å›æ‰¾åˆ°çš„æ–‡ä»¶ä¿¡æ¯
        file_info = []
        for file_path in possible_files:
            stat = file_path.stat()
            file_info.append(f"æ–‡ä»¶: {file_path.name}, å¤§å°: {stat.st_size} å­—èŠ‚, ä¿®æ”¹æ—¶é—´: {time.ctime(stat.st_mtime)}")
        
        return f"æ‰¾åˆ° {len(possible_files)} ä¸ªç›¸å…³ç»“æœæ–‡ä»¶:\n" + "\n".join(file_info)
        
    except Exception as e:
        return f"è·å–æœ€è¿‘åˆ†æç»“æœæ—¶å‡ºé”™: {str(e)}"


@mcp.resource("device://status")
def get_device_resource() -> str:
    """
    ä½œä¸ºèµ„æºæä¾›è®¾å¤‡çŠ¶æ€ä¿¡æ¯
    
    Returns:
        è®¾å¤‡çŠ¶æ€çš„æ–‡æœ¬æè¿°
    """
    try:
        info = get_device_info()
        
        status_text = f"è®¾å¤‡ç±»å‹: {info['device']}\n"
        status_text += f"CUDA å¯ç”¨: {info['cuda_available']}\n"
        
        if info['cuda_available']:
            status_text += f"CUDA ç‰ˆæœ¬: {info.get('cuda_version', 'Unknown')}\n"
            status_text += f"GPU æ•°é‡: {info.get('gpu_count', 0)}\n"
            status_text += f"å½“å‰ GPU: {info.get('gpu_name', 'Unknown')}\n"
            
            gpu_memory = info.get('gpu_memory', {})
            if gpu_memory:
                total_gb = gpu_memory.get('total', 0) / (1024**3)
                allocated_gb = gpu_memory.get('allocated', 0) / (1024**3)
                status_text += f"GPU å†…å­˜: {allocated_gb:.2f}GB / {total_gb:.2f}GB"
        
        analyzer_ready = analyzer is not None and analyzer._initialized if analyzer else False
        status_text += f"\nåˆ†æå™¨çŠ¶æ€: {'å°±ç»ª' if analyzer_ready else 'æœªåˆå§‹åŒ–'}"
        
        return status_text
        
    except Exception as e:
        return f"è·å–è®¾å¤‡çŠ¶æ€æ—¶å‡ºé”™: {str(e)}"


@mcp.prompt()
def debug_analysis_error(error_message: str, image_path: str = "") -> List[Message]:
    """
    ç”Ÿæˆè°ƒè¯•å›¾åƒåˆ†æé”™è¯¯çš„æç¤º
    
    Args:
        error_message: é”™è¯¯ä¿¡æ¯
        image_path: å¯é€‰çš„å›¾åƒè·¯å¾„
        
    Returns:
        è°ƒè¯•æç¤ºæ¶ˆæ¯åˆ—è¡¨
    """
    prompt_text = f"""æˆ‘åœ¨ä½¿ç”¨å›¾åƒå…ƒç´ åˆ†æå™¨æ—¶é‡åˆ°äº†é”™è¯¯ï¼š

é”™è¯¯ä¿¡æ¯: {error_message}
"""
    
    if image_path:
        prompt_text += f"å›¾åƒè·¯å¾„: {image_path}\n"
    
    prompt_text += """
è¯·å¸®æˆ‘åˆ†æå¯èƒ½çš„åŸå› å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚å¸¸è§é—®é¢˜åŒ…æ‹¬ï¼š

1. æ–‡ä»¶è·¯å¾„é—®é¢˜ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨ã€æƒé™é—®é¢˜ï¼‰
2. å›¾åƒæ ¼å¼ä¸æ”¯æŒ
3. æ¨¡å‹æ–‡ä»¶ç¼ºå¤±æˆ–æŸå
4. é…ç½®æ–‡ä»¶é—®é¢˜
5. GPU/CPU å†…å­˜ä¸è¶³
6. ä¾èµ–åº“ç‰ˆæœ¬å†²çª

è¯·æä¾›å…·ä½“çš„æ’æŸ¥æ­¥éª¤å’Œè§£å†³å»ºè®®ã€‚
"""
    
    return [
        Message(
            role="user",
            content=[
                TextContent(text=prompt_text)
            ]
        )
    ]


@mcp.prompt()
def optimize_analysis_settings(
    image_type: str = "screenshot",
    quality_priority: str = "balanced"
) -> List[Message]:
    """
    ç”Ÿæˆä¼˜åŒ–åˆ†æè®¾ç½®çš„æç¤º
    
    Args:
        image_type: å›¾åƒç±»å‹ (screenshot, document, ui, mixed)
        quality_priority: è´¨é‡ä¼˜å…ˆçº§ (speed, balanced, accuracy)
        
    Returns:
        ä¼˜åŒ–å»ºè®®æ¶ˆæ¯åˆ—è¡¨
    """
    prompt_text = f"""è¯·ä¸ºæˆ‘çš„å›¾åƒåˆ†æä»»åŠ¡æ¨èæœ€ä½³å‚æ•°è®¾ç½®ï¼š

å›¾åƒç±»å‹: {image_type}
è´¨é‡ä¼˜å…ˆçº§: {quality_priority}

å¯è°ƒæ•´çš„å‚æ•°åŒ…æ‹¬ï¼š
- box_threshold: æ£€æµ‹æ¡†ç½®ä¿¡åº¦é˜ˆå€¼ (0.01-1.0)
- save_annotated: æ˜¯å¦ä¿å­˜æ ‡æ³¨å›¾åƒ
- output_dir: è¾“å‡ºç›®å½•è®¾ç½®

è¯·æ ¹æ®æˆ‘çš„éœ€æ±‚æ¨èå…·ä½“çš„å‚æ•°å€¼ï¼Œå¹¶è§£é‡Šé€‰æ‹©è¿™äº›å€¼çš„åŸå› ã€‚
"""
    
    return [
        Message(
            role="user",
            content=[
                TextContent(text=prompt_text)
            ]
        )
    ]


if __name__ == "__main__":
    # é…ç½®æœåŠ¡å™¨ç«¯å£
    port_number = 8999
    
    print("ğŸ¯ å›¾åƒå…ƒç´ åˆ†æå™¨ FastMCP æœåŠ¡å™¨")
    print("=" * 50)
    
    # æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
    device_info = get_device_info()
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device_info['device']}")
    if device_info['cuda_available']:
        print(f"ğŸ® GPU: {device_info.get('gpu_name', 'Unknown')}")
    else:
        print("ğŸ’» ä½¿ç”¨ CPU æ¨¡å¼")
    
    print(f"\nğŸŒ æœåŠ¡ç«¯å£: {port_number}")
    print("\nğŸš€ å¯åŠ¨ FastMCP æœåŠ¡å™¨...")
    print("ğŸ“‹ å¯ç”¨å·¥å…·:")
    print("   â€¢ analyze_image_file - åˆ†æå›¾åƒæ–‡ä»¶")
    print("   â€¢ analyze_image_base64 - åˆ†æ Base64 å›¾åƒ")
    print("   â€¢ batch_analyze_images - æ‰¹é‡åˆ†æå›¾åƒ")
    print("   â€¢ get_device_status - è·å–è®¾å¤‡çŠ¶æ€")
    print("\nğŸ“š å¯ç”¨èµ„æº:")
    print("   â€¢ image://recent/{filename} - æœ€è¿‘åˆ†æç»“æœ")
    print("   â€¢ device://status - è®¾å¤‡çŠ¶æ€")
    print("\nğŸ’¡ å¯ç”¨æç¤º:")
    print("   â€¢ debug_analysis_error - è°ƒè¯•åˆ†æé”™è¯¯")
    print("   â€¢ optimize_analysis_settings - ä¼˜åŒ–åˆ†æè®¾ç½®")
    print("\n" + "=" * 50)
    
    # è¿è¡ŒæœåŠ¡å™¨
    mcp.run(transport="sse", host="0.0.0.0", port=port_number) 