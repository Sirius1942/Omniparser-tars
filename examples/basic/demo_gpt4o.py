#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
GPT-4o å›¾æ ‡è¯†åˆ«æ¼”ç¤ºè„šæœ¬
åŸºäº demo.ipynb æ”¹å†™ï¼Œä½¿ç”¨ GPT-4o æ›¿ä»£ Florence-2
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
import os
import sys
import time
import base64
import io
from PIL import Image
import torch
import pandas as pd

# å¯¼å…¥ OmniParser ç›¸å…³æ¨¡å—
from src.utils.utils import get_som_labeled_img, check_ocr_box, get_caption_model_processor, get_yolo_model
from src.utils.config import get_config

def main():
    print("ğŸš€ OmniParser + GPT-4o æ¼”ç¤º")
    print("=" * 50)
    
    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = "config.json"
    if not os.path.exists(config_path):
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·ç¡®ä¿ config.json å·²æ­£ç¡®è®¾ç½®")
        return
    
    try:
        config = get_config(config_path)
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   ğŸ”§ APIç«¯ç‚¹: {config.get_openai_base_url()}")
        print(f"   ğŸ¤– ä½¿ç”¨æ¨¡å‹: {config.get_openai_model()}")
        print(f"   ğŸ“¦ æ‰¹å¤„ç†å¤§å°: {config.get_batch_size()}")
    except Exception as e:
        print(f"âŒ é…ç½®é”™è¯¯: {e}")
        return
    
    # 2. è®¾ç½®è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 3. åŠ è½½YOLOæ¨¡å‹
    model_path = 'weights/icon_detect/model.pt'
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    print("\nğŸ“¥ åŠ è½½YOLOå›¾æ ‡æ£€æµ‹æ¨¡å‹...")
    som_model = get_yolo_model(model_path)
    som_model.to(device)
    print(f'âœ… æ¨¡å‹å·²åŠ è½½åˆ° {device}')
    
    # 4. é…ç½®GPT-4oå›¾æ ‡æè¿°æ¨¡å‹
    print("\nğŸ¤– é…ç½®GPT-4oå›¾æ ‡æè¿°æ¨¡å‹...")
    caption_model_processor = get_caption_model_processor(
        model_name="gpt4o", 
        model_name_or_path=config.get_openai_model(),
        device=device
    )
    print("âœ… GPT-4oæ¨¡å‹é…ç½®å®Œæˆ")
    
    # 5. å¤„ç†æµ‹è¯•å›¾åƒ
    test_images = [
        'imgs/word.png',
        'imgs/windows_home.png',
        'imgs/google_page.png'
    ]
    
    for image_path in test_images:
        if not os.path.exists(image_path):
            print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„å›¾åƒ: {image_path}")
            continue
            
        print(f"\nğŸ–¼ï¸  å¤„ç†å›¾åƒ: {image_path}")
        print("-" * 40)
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path)
        image_rgb = image.convert('RGB')
        print(f'ğŸ“ å›¾åƒå°ºå¯¸: {image.size}')
        
        # é…ç½®è¾¹ç•Œæ¡†ç»˜åˆ¶å‚æ•°
        box_overlay_ratio = max(image.size) / 3200
        draw_bbox_config = {
            'text_scale': 0.8 * box_overlay_ratio,
            'text_thickness': max(int(2 * box_overlay_ratio), 1),
            'text_padding': max(int(3 * box_overlay_ratio), 1),
            'thickness': max(int(3 * box_overlay_ratio), 1),
        }
        BOX_TRESHOLD = 0.05
        
        # è®¡æ—¶å¼€å§‹
        start_time = time.time()
        
        try:
            # OCR æ£€æµ‹
            print("ğŸ” è¿›è¡ŒOCRæ–‡æœ¬æ£€æµ‹...")
            ocr_start = time.time()
            ocr_bbox_rslt, is_goal_filtered = check_ocr_box(
                image_path, 
                display_img=False, 
                output_bb_format='xyxy', 
                goal_filtering=None, 
                easyocr_args={'paragraph': False, 'text_threshold': 0.9}, 
                use_paddleocr=True
            )
            text, ocr_bbox = ocr_bbox_rslt
            ocr_time = time.time() - ocr_start
            print(f"   ğŸ“ OCRå®Œæˆï¼Œæ£€æµ‹åˆ° {len(text)} ä¸ªæ–‡æœ¬åŒºåŸŸ (è€—æ—¶: {ocr_time:.2f}s)")
            
            # å›¾æ ‡æ£€æµ‹å’Œæè¿°
            print("ğŸ¯ è¿›è¡Œå›¾æ ‡æ£€æµ‹å’ŒGPT-4oæè¿°...")
            caption_start = time.time()
            
            dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(
                image_path, 
                som_model, 
                BOX_TRESHOLD=BOX_TRESHOLD, 
                output_coord_in_ratio=True, 
                ocr_bbox=ocr_bbox,
                draw_bbox_config=draw_bbox_config, 
                caption_model_processor=caption_model_processor, 
                ocr_text=text,
                use_local_semantics=True, 
                iou_threshold=0.7, 
                scale_img=False
                # batch_size ä¼šä»é…ç½®æ–‡ä»¶è‡ªåŠ¨è¯»å–
            )
            
            caption_time = time.time() - caption_start
            total_time = time.time() - start_time
            
            print(f"   âœ… å›¾æ ‡è¯†åˆ«å®Œæˆ (è€—æ—¶: {caption_time:.2f}s)")
            print(f"   ğŸ¯ æ€»å…±æ£€æµ‹åˆ° {len(parsed_content_list)} ä¸ªå…ƒç´ ")
            print(f"   â±ï¸  æ€»è€—æ—¶: {total_time:.2f}s")
            
            # ä¿å­˜æ ‡æ³¨å›¾åƒ
            output_path = f"output_gpt4o_{os.path.basename(image_path)}"
            image_data = base64.b64decode(dino_labled_img)
            output_image = Image.open(io.BytesIO(image_data))
            output_image.save(output_path)
            print(f"   ğŸ’¾ æ ‡æ³¨å›¾åƒå·²ä¿å­˜: {output_path}")
            
            # æ˜¾ç¤ºè§£æç»“æœ
            print(f"\nğŸ“‹ è§£æç»“æœè¯¦æƒ…:")
            print("=" * 60)
            
            # åˆ›å»ºDataFrameæ˜¾ç¤ºç»“æœï¼ˆç±»ä¼¼notebookä¸­çš„æ˜¾ç¤ºï¼‰
            df = pd.DataFrame(parsed_content_list)
            df['ID'] = range(len(df))
            
            # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
            text_items = [item for item in parsed_content_list if item.get('type') == 'text']
            icon_items = [item for item in parsed_content_list if item.get('type') == 'icon']
            
            print(f"ğŸ“ æ–‡æœ¬å…ƒç´  ({len(text_items)} ä¸ª):")
            for i, item in enumerate(text_items):
                content = item.get('content', 'N/A')
                bbox = item.get('bbox', [])
                print(f"   {i+1:2d}. {content}")
                if bbox:
                    print(f"       ä½ç½®: ({bbox[0]:.3f}, {bbox[1]:.3f}, {bbox[2]:.3f}, {bbox[3]:.3f})")
            
            print(f"\nğŸ¯ å›¾æ ‡å…ƒç´  ({len(icon_items)} ä¸ª) - GPT-4oæè¿°:")
            for i, item in enumerate(icon_items):
                content = item.get('content', 'N/A')
                bbox = item.get('bbox', [])
                print(f"   {i+1:2d}. {content}")
                if bbox:
                    print(f"       ä½ç½®: ({bbox[0]:.3f}, {bbox[1]:.3f}, {bbox[2]:.3f}, {bbox[3]:.3f})")
            
            # ä¿å­˜è¯¦ç»†ç»“æœåˆ°CSV
            csv_path = f"results_gpt4o_{os.path.basename(image_path).replace('.png', '.csv')}"
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "="*60)

if __name__ == "__main__":
    main()
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - output_gpt4o_*.png: æ ‡æ³¨å›¾åƒ")
    print("  - results_gpt4o_*.csv: è¯¦ç»†ç»“æœæ•°æ®") 