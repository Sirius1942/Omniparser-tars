#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å›¾åƒå…ƒç´ åˆ†æå™¨
æä¾›å›¾åƒä¸­æ–‡æœ¬å’Œå›¾æ ‡çš„æ£€æµ‹ã€è¯†åˆ«å’Œæè¿°åŠŸèƒ½
åŸºäº OmniParser + GPT-4o å®ç°
"""

import os
import time
import base64
import io
from typing import Dict, List, Tuple, Optional, Any
from PIL import Image
import torch
import pandas as pd

# å¯¼å…¥ OmniParser ç›¸å…³æ¨¡å—
from src.utils.utils import get_som_labeled_img, check_ocr_box, get_caption_model_processor, get_yolo_model
from src.utils.config import get_config


class ImageElementAnalyzer:
    """å›¾åƒå…ƒç´ åˆ†æå™¨ç±»"""
    
    def __init__(self, model_path: str = 'weights/icon_detect/model.pt', config_path: str = "config.json"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            model_path: YOLOæ¨¡å‹è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.model_path = model_path
        self.config_path = config_path
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.som_model = None
        self.caption_model_processor = None
        self.config = None
        self._initialized = False
    
    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–æ¨¡å‹å’Œé…ç½®
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            # åŠ è½½é…ç½®
            if not os.path.exists(self.config_path):
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            
            self.config = get_config(self.config_path)
            
            # åŠ è½½YOLOæ¨¡å‹
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            
            self.som_model = get_yolo_model(self.model_path)
            self.som_model.to(self.device)
            
            # é…ç½®GPT-4oå›¾æ ‡æè¿°æ¨¡å‹
            self.caption_model_processor = get_caption_model_processor(
                model_name="gpt4o", 
                model_name_or_path=self.config.get_openai_model(),
                device=self.device
            )
            
            self._initialized = True
            return True
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def analyze_image(self, image_path: str, box_threshold: float = 0.05, 
                     save_annotated: bool = False, output_dir: str = ".", 
                     verbose: bool = True) -> Dict[str, Any]:
        """
        åˆ†æå›¾åƒä¸­çš„å…ƒç´ 
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            box_threshold: æ£€æµ‹æ¡†é˜ˆå€¼
            save_annotated: æ˜¯å¦ä¿å­˜æ ‡æ³¨å›¾åƒ
            output_dir: è¾“å‡ºç›®å½•
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            dict: åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - success: bool, æ˜¯å¦æˆåŠŸ
                - elements: list, æ£€æµ‹åˆ°çš„å…ƒç´ åˆ—è¡¨
                - text_elements: list, æ–‡æœ¬å…ƒç´ 
                - icon_elements: list, å›¾æ ‡å…ƒç´   
                - annotated_image_path: str, æ ‡æ³¨å›¾åƒè·¯å¾„ï¼ˆå¦‚æœä¿å­˜ï¼‰
                - processing_time: dict, å„é˜¶æ®µè€—æ—¶
                - image_info: dict, å›¾åƒåŸºæœ¬ä¿¡æ¯
                - error: str, é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        if not self._initialized:
            if not self.initialize():
                return {"success": False, "error": "æ¨¡å‹åˆå§‹åŒ–å¤±è´¥"}
        
        if not os.path.exists(image_path):
            return {"success": False, "error": f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}"}
        
        try:
            start_time = time.time()
            
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path)
            image_rgb = image.convert('RGB')
            image_info = {
                "path": image_path,
                "size": image.size,
                "mode": image.mode,
                "format": image.format
            }
            
            if verbose:
                print(f"ğŸ–¼ï¸  åˆ†æå›¾åƒ: {os.path.basename(image_path)}")
                print(f"ğŸ“ å›¾åƒå°ºå¯¸: {image.size}")
            
            # é…ç½®è¾¹ç•Œæ¡†ç»˜åˆ¶å‚æ•°
            box_overlay_ratio = max(image.size) / 3200
            draw_bbox_config = {
                'text_scale': 0.8 * box_overlay_ratio,
                'text_thickness': max(int(2 * box_overlay_ratio), 1),
                'text_padding': max(int(3 * box_overlay_ratio), 1),
                'thickness': max(int(3 * box_overlay_ratio), 1),
            }
            
            processing_time = {}
            
            # OCR æ£€æµ‹
            if verbose:
                print("ğŸ” è¿›è¡ŒOCRæ–‡æœ¬æ£€æµ‹...")
            ocr_start = time.time()
            
            ocr_bbox_rslt, is_goal_filtered = check_ocr_box(
                image_path, 
                display_img=False, 
                output_bb_format='xyxy', 
                goal_filtering=None, 
                easyocr_args={'paragraph': False, 'text_threshold': 0.9}, 
                use_paddleocr=True
            )
            text, ocr_bbox = ocr_bbox_rslt
            processing_time['ocr'] = time.time() - ocr_start
            
            if verbose:
                print(f"   ğŸ“ OCRå®Œæˆï¼Œæ£€æµ‹åˆ° {len(text)} ä¸ªæ–‡æœ¬åŒºåŸŸ (è€—æ—¶: {processing_time['ocr']:.2f}s)")
            
            # å›¾æ ‡æ£€æµ‹å’Œæè¿°
            if verbose:
                print("ğŸ¯ è¿›è¡Œå›¾æ ‡æ£€æµ‹å’ŒGPT-4oæè¿°...")
            caption_start = time.time()
            
            dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(
                image_path, 
                self.som_model, 
                BOX_TRESHOLD=box_threshold, 
                output_coord_in_ratio=True, 
                ocr_bbox=ocr_bbox,
                draw_bbox_config=draw_bbox_config, 
                caption_model_processor=self.caption_model_processor, 
                ocr_text=text,
                use_local_semantics=True, 
                iou_threshold=0.7, 
                scale_img=False
            )
            
            processing_time['caption'] = time.time() - caption_start
            processing_time['total'] = time.time() - start_time
            
            if verbose:
                print(f"   âœ… å›¾æ ‡è¯†åˆ«å®Œæˆ (è€—æ—¶: {processing_time['caption']:.2f}s)")
                print(f"   ğŸ¯ æ€»å…±æ£€æµ‹åˆ° {len(parsed_content_list)} ä¸ªå…ƒç´ ")
                print(f"   â±ï¸  æ€»è€—æ—¶: {processing_time['total']:.2f}s")
            
            # åˆ†ç±»å…ƒç´ 
            text_elements = [item for item in parsed_content_list if item.get('type') == 'text']
            icon_elements = [item for item in parsed_content_list if item.get('type') == 'icon']
            
            # ä¿å­˜æ ‡æ³¨å›¾åƒï¼ˆå¦‚æœéœ€è¦ï¼‰
            annotated_image_path = None
            if save_annotated:
                output_filename = f"annotated_{os.path.basename(image_path)}"
                annotated_image_path = os.path.join(output_dir, output_filename)
                
                image_data = base64.b64decode(dino_labled_img)
                output_image = Image.open(io.BytesIO(image_data))
                output_image.save(annotated_image_path)
                
                if verbose:
                    print(f"   ğŸ’¾ æ ‡æ³¨å›¾åƒå·²ä¿å­˜: {annotated_image_path}")
            
            return {
                "success": True,
                "elements": parsed_content_list,
                "text_elements": text_elements,
                "icon_elements": icon_elements,
                "annotated_image_path": annotated_image_path,
                "annotated_image_base64": dino_labled_img if not save_annotated else None,
                "label_coordinates": label_coordinates,
                "processing_time": processing_time,
                "image_info": image_info,
                "element_count": {
                    "total": len(parsed_content_list),
                    "text": len(text_elements),
                    "icon": len(icon_elements)
                }
            }
            
        except Exception as e:
            import traceback
            error_msg = f"åˆ†æå›¾åƒæ—¶å‡ºé”™: {e}"
            if verbose:
                print(f"âŒ {error_msg}")
                traceback.print_exc()
            
            return {
                "success": False,
                "error": error_msg,
                "traceback": traceback.format_exc()
            }
    
    def batch_analyze(self, image_paths: List[str], **kwargs) -> Dict[str, Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æå¤šä¸ªå›¾åƒ
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            **kwargs: analyze_imageæ–¹æ³•çš„å…¶ä»–å‚æ•°
            
        Returns:
            dict: æ¯ä¸ªå›¾åƒçš„åˆ†æç»“æœï¼Œé”®ä¸ºå›¾åƒè·¯å¾„
        """
        results = {}
        verbose = kwargs.get('verbose', True)
        
        if verbose:
            print(f"ğŸ”„ å¼€å§‹æ‰¹é‡åˆ†æ {len(image_paths)} ä¸ªå›¾åƒ...")
        
        for i, image_path in enumerate(image_paths, 1):
            if verbose:
                print(f"\n[{i}/{len(image_paths)}] å¤„ç†: {os.path.basename(image_path)}")
            
            result = self.analyze_image(image_path, **kwargs)
            results[image_path] = result
            
            if result["success"] and verbose:
                count = result["element_count"]
                print(f"âœ… å®Œæˆ - æ–‡æœ¬:{count['text']} å›¾æ ‡:{count['icon']}")
            elif not result["success"] and verbose:
                print(f"âŒ å¤±è´¥ - {result.get('error', 'Unknown error')}")
        
        return results


# ä¾¿æ·å‡½æ•°
def analyze_single_image(image_path: str, model_path: str = 'weights/icon_detect/model.pt',
                        config_path: str = "config.json", **kwargs) -> Dict[str, Any]:
    """
    åˆ†æå•ä¸ªå›¾åƒçš„ä¾¿æ·å‡½æ•°
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        model_path: æ¨¡å‹è·¯å¾„
        config_path: é…ç½®è·¯å¾„
        **kwargs: å…¶ä»–åˆ†æå‚æ•°
        
    Returns:
        dict: åˆ†æç»“æœ
    """
    analyzer = ImageElementAnalyzer(model_path, config_path)
    return analyzer.analyze_image(image_path, **kwargs)


def get_element_descriptions(image_path: str, element_type: str = "all", 
                           model_path: str = 'weights/icon_detect/model.pt',
                           config_path: str = "config.json") -> List[Dict[str, Any]]:
    """
    è·å–å›¾åƒå…ƒç´ æè¿°çš„ç®€åŒ–å‡½æ•°
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        element_type: å…ƒç´ ç±»å‹ ("text", "icon", "all")
        model_path: æ¨¡å‹è·¯å¾„  
        config_path: é…ç½®è·¯å¾„
        
    Returns:
        list: å…ƒç´ æè¿°åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«contentå’Œbboxä¿¡æ¯
    """
    result = analyze_single_image(image_path, model_path, config_path, verbose=False)
    
    if not result["success"]:
        return []
    
    if element_type == "text":
        return result["text_elements"]
    elif element_type == "icon":
        return result["icon_elements"]
    else:  # "all"
        return result["elements"]


def get_coordinates_by_description(image_path: str, description: str, 
                                 model_path: str = 'weights/icon_detect/model.pt',
                                 config_path: str = "config.json") -> Optional[List[float]]:
    """
    æ ¹æ®æè¿°æŸ¥æ‰¾å…ƒç´ åæ ‡
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        description: å…ƒç´ æè¿°
        model_path: æ¨¡å‹è·¯å¾„
        config_path: é…ç½®è·¯å¾„
        
    Returns:
        list: åæ ‡ [x1, y1, x2, y2] æˆ– None
    """
    elements = get_element_descriptions(image_path, "all", model_path, config_path)
    
    # ç®€å•çš„æ–‡æœ¬åŒ¹é…æŸ¥æ‰¾
    description_lower = description.lower()
    for element in elements:
        content = element.get('content', '').lower()
        if description_lower in content or content in description_lower:
            return element.get('bbox')
    
    return None


if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    print("ğŸš€ å›¾åƒå…ƒç´ åˆ†æå™¨ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # æµ‹è¯•å›¾åƒ
    test_images = [
        'imgs/word.png',
        'imgs/windows_home.png', 
        'imgs/google_page.png'
    ]
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ImageElementAnalyzer()
    
    if not analyzer.initialize():
        print("âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥")
        exit(1)
    
    # åˆ†æå•ä¸ªå›¾åƒ
    for image_path in test_images:
        if os.path.exists(image_path):
            print(f"\nåˆ†æå›¾åƒ: {image_path}")
            result = analyzer.analyze_image(
                image_path, 
                save_annotated=True,
                output_dir="result"
            )
            
            if result["success"]:
                print(f"âœ… åˆ†ææˆåŠŸï¼Œæ£€æµ‹åˆ° {result['element_count']['total']} ä¸ªå…ƒç´ ")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ªå›¾æ ‡æè¿°
                icons = result["icon_elements"][:3]  # åªæ˜¾ç¤ºå‰3ä¸ª
                if icons:
                    print("ğŸ¯ å›¾æ ‡æè¿°ç¤ºä¾‹:")
                    for i, icon in enumerate(icons, 1):
                        content = icon.get('content', 'N/A')
                        bbox = icon.get('bbox', [])
                        print(f"   {i}. {content}")
                        if bbox:
                            print(f"      åæ ‡: [{bbox[0]:.3f}, {bbox[1]:.3f}, {bbox[2]:.3f}, {bbox[3]:.3f}]")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result.get('error')}")
        else:
            print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„å›¾åƒ: {image_path}")
    
    print("\nğŸ‰ ç¤ºä¾‹å®Œæˆï¼") 