#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Phoenix Vision MCP Server å¯åŠ¨è„šæœ¬
ğŸ”¥ å¯åŠ¨å‡¤å‡°è§†è§‰å›¾åƒåˆ†ææœåŠ¡
"""

import asyncio
import os
import sys
from pathlib import Path

# ç¡®ä¿èƒ½å¯¼å…¥ MCP æœåŠ¡å™¨
sys.path.append(str(Path(__file__).parent))

from phoenix_vision_mcp_server import main as start_phoenix_vision


def check_requirements():
    """æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶å’Œä¾èµ–"""
    errors = []
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = "weights/icon_detect/model.pt"
    if not os.path.exists(model_path):
        errors.append(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        errors.append("   è¯·å…ˆä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = "config.json"
    if not os.path.exists(config_path):
        if os.path.exists("config.example.json"):
            errors.append(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            errors.append("   è¯·å¤åˆ¶ config.example.json ä¸º config.json å¹¶é…ç½®")
        else:
            errors.append(f"âŒ é…ç½®æ–‡ä»¶å’Œç¤ºä¾‹éƒ½ä¸å­˜åœ¨")
    
    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    try:
        import torch
        import fastapi
        import uvicorn
        import aiohttp
    except ImportError as e:
        errors.append(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        errors.append("   è¯·è¿è¡Œ: pip install -r requirements.txt")
    
    return errors


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ Phoenix Vision MCP Server å¯åŠ¨å™¨")
    print("ğŸŒŒ ä¸ Nebula Scout Client å®Œç¾é…åˆçš„å›¾åƒåˆ†ææœåŠ¡")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    errors = check_requirements()
    if errors:
        print("âš ï¸ å¯åŠ¨å‰æ£€æŸ¥å‘ç°é—®é¢˜:")
        for error in errors:
            print(error)
        print("\nè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡æ–°å¯åŠ¨")
        return
    
    print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
    
    # æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
    try:
        import torch
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ–¥ï¸  æ£€æµ‹åˆ°è®¾å¤‡: {device}")
        
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"ğŸ® GPU: {gpu_name}")
        else:
            print("ğŸ’» ä½¿ç”¨ CPU æ¨¡å¼")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•æ£€æµ‹è®¾å¤‡ä¿¡æ¯: {e}")
    
    # å¯åŠ¨æœåŠ¡å™¨
    print("\nğŸŒ å¯åŠ¨ MCP æœåŠ¡å™¨...")
    print("ğŸ“¡ æ”¯æŒ SSE (Server-Sent Events) æµå¼é€šä¿¡")
    print("ğŸ”— API æ–‡æ¡£å°†åœ¨å¯åŠ¨åå¯ç”¨: http://localhost:8000/docs")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    print("=" * 50)
    
    try:
        await start_mcp_server(
            model_path="weights/icon_detect/model.pt",
            config_path="config.json",
            port=8000
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 