#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Phoenix Vision FastMCP Server - å‡¤å‡°è§†è§‰FastMCPæœåŠ¡ç«¯
åŸºäº FastMCP çš„æ™ºèƒ½å›¾åƒå…ƒç´ åˆ†ææœåŠ¡
ğŸ”¥ Phoenix Vision - æ¶…æ§ƒé‡ç”Ÿçš„å›¾åƒè¯†åˆ«èƒ½åŠ›
"""

import os
import sys
import json
import time
import base64
import traceback
from pathlib import Path
from typing import Any, Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from fastmcp import FastMCP

# å°è¯•å¯¼å…¥å›¾åƒåˆ†æå™¨
try:
    from src.utils.image_element_analyzer import ImageElementAnalyzer
    analyzer_available = True
except ImportError as e:
    print(f"âš ï¸ æ— æ³•å¯¼å…¥å›¾åƒåˆ†æå™¨: {e}")
    analyzer_available = False

# åˆ›å»º Phoenix Vision æœåŠ¡å™¨
mcp = FastMCP("phoenix-vision")

# å…¨å±€åˆ†æå™¨å®ä¾‹
analyzer: Optional[ImageElementAnalyzer] = None

def initialize_analyzer() -> bool:
    """åˆå§‹åŒ–å›¾åƒåˆ†æå™¨"""
    global analyzer
    
    if not analyzer_available:
        print("âŒ å›¾åƒåˆ†æå™¨ä¸å¯ç”¨")
        return False
    
    if analyzer is not None:
        return True
    
    try:
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–å›¾åƒåˆ†æå™¨...")
        
        # æ£€æŸ¥æ¨¡å‹å’Œé…ç½®æ–‡ä»¶ - ä½¿ç”¨ç»å¯¹è·¯å¾„
        model_path = os.path.join(project_root, 'weights/icon_detect/model.pt')
        config_path = os.path.join(project_root, "config.json")
        
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"ğŸ“ é…ç½®è·¯å¾„: {config_path}")
        
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
            
        if not os.path.exists(config_path):
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
        original_cwd = os.getcwd()
        os.chdir(project_root)
        
        try:
            analyzer = ImageElementAnalyzer(model_path, config_path)
            success = analyzer.initialize()
        finally:
            # æ¢å¤åŸå·¥ä½œç›®å½•
            os.chdir(original_cwd)
        
        if success:
            print("âœ… åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        else:
            print("âŒ åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–åˆ†æå™¨æ—¶å‡ºé”™: {e}")
        traceback.print_exc()
        return False

@mcp.tool()
def analyze_image_file(
    image_path: str,
    box_threshold: float = 0.05,
    save_annotated: bool = True,
    output_dir: str = "./results"
) -> dict:
    """åˆ†æå›¾åƒæ–‡ä»¶ä¸­çš„æ–‡æœ¬å’Œå›¾æ ‡å…ƒç´ """
    
    # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    if not initialize_analyzer():
        return {
            "success": False,
            "error": "åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥",
            "timestamp": time.time()
        }
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            return {
                "success": False,
                "error": f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}",
                "timestamp": time.time()
            }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ–¼ï¸  åˆ†æå›¾åƒ: {os.path.basename(image_path)}")
        
        # æ‰§è¡Œåˆ†æ
        result = analyzer.analyze_image(
            image_path,
            box_threshold=box_threshold,
            save_annotated=save_annotated,
            output_dir=output_dir,
            verbose=True
        )
        
        # æ·»åŠ æ—¶é—´æˆ³
        result["timestamp"] = time.time()
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"åˆ†æå›¾åƒæ—¶å‡ºé”™: {str(e)}",
            "timestamp": time.time()
        }

@mcp.tool()
def analyze_image_base64(
    image_base64: str,
    box_threshold: float = 0.05,
    save_annotated: bool = True,
    output_dir: str = "./results"
) -> dict:
    """åˆ†æ Base64 ç¼–ç çš„å›¾åƒ"""
    
    # ç¡®ä¿åˆ†æå™¨å·²åˆå§‹åŒ–
    if not initialize_analyzer():
        return {
            "success": False,
            "error": "åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥",
            "timestamp": time.time()
        }
    
    try:
        # ç§»é™¤å¯èƒ½çš„å‰ç¼€
        if "," in image_base64:
            image_base64 = image_base64.split(",")[1]
        
        # è§£ç å›¾åƒ
        from PIL import Image
        import io
        
        image_data = base64.b64decode(image_base64)
        image = Image.open(io.BytesIO(image_data))
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        timestamp = int(time.time() * 1000)
        temp_path = f"temp_fastmcp_{timestamp}.png"
        image.save(temp_path)
        
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            print(f"ğŸ–¼ï¸  åˆ†æ Base64 å›¾åƒ (å¤§å°: {image.size})")
            
            # æ‰§è¡Œåˆ†æ
            result = analyzer.analyze_image(
                temp_path,
                box_threshold=box_threshold,
                save_annotated=save_annotated,
                output_dir=output_dir,
                verbose=True
            )
            
            # æ·»åŠ æ—¶é—´æˆ³
            result["timestamp"] = time.time()
            
            return result
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)
                
    except Exception as e:
        return {
            "success": False,
            "error": f"åˆ†æ Base64 å›¾åƒæ—¶å‡ºé”™: {str(e)}",
            "timestamp": time.time()
        }

@mcp.tool()
def get_device_status() -> dict:
    """è·å–è®¾å¤‡å’Œåˆ†æå™¨çŠ¶æ€ä¿¡æ¯"""
    try:
        import torch
        
        # è·å–è®¾å¤‡ä¿¡æ¯
        device_info = {
            "device": 'cuda' if torch.cuda.is_available() else 'cpu',
            "cuda_available": torch.cuda.is_available(),
        }
        
        if torch.cuda.is_available():
            device_info.update({
                "cuda_version": torch.version.cuda,
                "gpu_count": torch.cuda.device_count(),
                "current_gpu": torch.cuda.current_device(),
                "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else None,
                "gpu_memory": {
                    "total": torch.cuda.get_device_properties(0).total_memory if torch.cuda.device_count() > 0 else 0,
                    "allocated": torch.cuda.memory_allocated(0) if torch.cuda.device_count() > 0 else 0,
                    "cached": torch.cuda.memory_reserved(0) if torch.cuda.device_count() > 0 else 0
                }
            })
        
        # æ£€æŸ¥åˆ†æå™¨çŠ¶æ€
        analyzer_status = {
            "initialized": analyzer is not None,
            "ready": analyzer is not None and analyzer._initialized if analyzer else False
        }
        
        result = {
            "success": True,
            "device_info": device_info,
            "analyzer_status": analyzer_status,
            "timestamp": time.time()
        }
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–è®¾å¤‡çŠ¶æ€å¤±è´¥: {str(e)}",
            "timestamp": time.time()
        }

@mcp.resource("phoenix://results")
def get_results_directory() -> str:
    """è·å–åˆ†æç»“æœç›®å½•ä¿¡æ¯"""
    try:
        results_dir = Path(os.path.join(project_root, "results"))
        
        if not results_dir.exists():
            return json.dumps({
                "directory": str(results_dir.absolute()),
                "files": [],
                "count": 0,
                "message": "ç»“æœç›®å½•ä¸å­˜åœ¨"
            }, ensure_ascii=False, indent=2)
        
        files = []
        for file_path in results_dir.iterdir():
            if file_path.is_file():
                stat = file_path.stat()
                files.append({
                    "name": file_path.name,
                    "size": stat.st_size,
                    "modified": time.ctime(stat.st_mtime)
                })
        
        return json.dumps({
            "directory": str(results_dir.absolute()),
            "files": files,
            "count": len(files)
        }, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "error": f"è·å–ç»“æœç›®å½•å¤±è´¥: {str(e)}",
            "timestamp": time.time()
        }, ensure_ascii=False, indent=2)

@mcp.resource("phoenix://config")
def get_analyzer_config() -> str:
    """è·å–åˆ†æå™¨é…ç½®ä¿¡æ¯"""
    try:
        config_info = {
            "initialized": analyzer is not None,
            "ready": analyzer is not None and analyzer._initialized if analyzer else False,
            "model_path": os.path.join(project_root, "weights/icon_detect/model.pt"),
            "config_path": os.path.join(project_root, "config.json"),
            "analyzer_available": analyzer_available
        }
        
        if analyzer:
            config_info.update({
                "device": analyzer.device,
                "model_loaded": analyzer.som_model is not None,
                "caption_model_loaded": analyzer.caption_model_processor is not None
            })
        
        return json.dumps(config_info, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return json.dumps({
            "error": f"è·å–é…ç½®ä¿¡æ¯å¤±è´¥: {str(e)}",
            "timestamp": time.time()
        }, ensure_ascii=False, indent=2)

@mcp.prompt()
def analyze_image_tips(image_type: str = "general") -> str:
    """å›¾åƒåˆ†æä½¿ç”¨æç¤ºå’Œæœ€ä½³å®è·µ"""
    return f"""
# ğŸ”¥ Phoenix Vision å›¾åƒåˆ†æä½¿ç”¨æç¤º

## å›¾åƒç±»å‹: {image_type}

### ğŸ¯ æœ€ä½³å®è·µ:
1. **å›¾åƒè´¨é‡**: ç¡®ä¿å›¾åƒæ¸…æ™°ï¼Œåˆ†è¾¨ç‡é€‚ä¸­ (æ¨è 800-3200px)
2. **æ£€æµ‹é˜ˆå€¼**: 
   - å¤æ‚å›¾åƒ: box_threshold = 0.03-0.05
   - ç®€å•å›¾åƒ: box_threshold = 0.05-0.1
3. **è¾“å‡ºç›®å½•**: ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–ç¡®ä¿ç›®å½•å­˜åœ¨
4. **æ–‡ä»¶æ ¼å¼**: æ”¯æŒ PNG, JPG, JPEG, BMP

### ğŸ“Š å‚æ•°å»ºè®®:
- **æˆªå›¾åˆ†æ**: box_threshold=0.05, save_annotated=true
- **æ–‡æ¡£åˆ†æ**: box_threshold=0.03, save_annotated=true  
- **UIç•Œé¢**: box_threshold=0.05, save_annotated=true

### âš ï¸ æ³¨æ„äº‹é¡¹:
- é¦–æ¬¡è¿è¡Œéœ€è¦åˆå§‹åŒ–æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
- GPU æ¨¡å¼æ¯” CPU æ¨¡å¼å¿« 3-5 å€
- å¤§å›¾åƒ (>5MB) å¤„ç†æ—¶é—´è¾ƒé•¿

### ğŸš€ å¿«é€Ÿå¼€å§‹:
```python
# åˆ†æå›¾åƒæ–‡ä»¶
result = await mcp_client.call_tool("analyze_image_file", {{
    "image_path": "your_image.png",
    "box_threshold": 0.05,
    "save_annotated": True
}})
```
"""

if __name__ == "__main__":
    print("ğŸ”¥ Phoenix Vision FastMCP æœåŠ¡å™¨")
    print("=" * 50)
    
    # æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
    try:
        import torch
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}")
        if torch.cuda.is_available():
            print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        else:
            print("ğŸ’» ä½¿ç”¨ CPU æ¨¡å¼")
    except ImportError:
        print("âš ï¸ PyTorch æœªå®‰è£…")
    
    print(f"\nğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"ğŸ“‹ åˆ†æå™¨å¯ç”¨: {'âœ…' if analyzer_available else 'âŒ'}")
    
    print("\nğŸ”§ å¯ç”¨å·¥å…·:")
    print("   â€¢ analyze_image_file - åˆ†æå›¾åƒæ–‡ä»¶")
    print("   â€¢ analyze_image_base64 - åˆ†æ Base64 å›¾åƒ") 
    print("   â€¢ get_device_status - è·å–è®¾å¤‡çŠ¶æ€")
    print("\nğŸ“š å¯ç”¨èµ„æº:")
    print("   â€¢ phoenix://results - åˆ†æç»“æœç›®å½•")
    print("   â€¢ phoenix://config - åˆ†æå™¨é…ç½®")
    print("\nğŸ’¡ å¯ç”¨æç¤º:")
    print("   â€¢ analyze_image_tips - ä½¿ç”¨æç¤º")
    print("\nğŸš€ å¯åŠ¨ FastMCP æœåŠ¡å™¨...")
    print("=" * 50)
    
    # ä½¿ç”¨ stdio ä¼ è¾“åè®®è¿è¡ŒæœåŠ¡å™¨
    mcp.run(transport="sse", host="0.0.0.0", port=8923) 