#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åŸºäºLangGraphçš„PDCAå¾ªç¯å·¥ä½œä»»åŠ¡å¤„ç†Agent Demo
PDCA: Plan-Do-Check-Act å¾ªç¯
"""

import json
import asyncio
from typing import TypedDict, List, Dict, Any, Annotated
from datetime import datetime

from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# å®šä¹‰çŠ¶æ€ç±»å‹
class PDCAState(TypedDict):
    """PDCAå¾ªç¯çŠ¶æ€"""
    task_description: str  # ä»»åŠ¡æè¿°
    current_phase: str     # å½“å‰é˜¶æ®µï¼šplan, do, check, act
    plan: Dict[str, Any]   # è®¡åˆ’è¯¦æƒ…
    execution_log: List[str]  # æ‰§è¡Œæ—¥å¿—
    check_results: Dict[str, Any]  # æ£€æŸ¥ç»“æœ
    improvement_actions: List[str]  # æ”¹è¿›è¡ŒåŠ¨
    cycle_count: int       # å¾ªç¯æ¬¡æ•°
    is_complete: bool      # æ˜¯å¦å®Œæˆ
    messages: List[Any]    # å¯¹è¯å†å²

class PDCAAgent:
    """PDCAå¾ªç¯å·¥ä½œä»»åŠ¡å¤„ç†Agent"""
    
    def __init__(self, config_path: str = "config.json"):
        """åˆå§‹åŒ–Agent"""
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        openai_config = config.get("openai", {})
        
        # åˆå§‹åŒ–LLM (æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹)
        self.llm = ChatOpenAI(
            api_key=openai_config["api_key"],
            base_url=openai_config["base_url"],
            model=openai_config["model"],  # ä½¿ç”¨é…ç½®ä¸­çš„Qwen3-32B
            temperature=0.3,
            max_tokens=2000
        )
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨
        self.memory = MemorySaver()
        
        # æ„å»ºçŠ¶æ€å›¾
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºPDCAå¾ªç¯çŠ¶æ€å›¾"""
        workflow = StateGraph(PDCAState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("plan", self._plan_phase)
        workflow.add_node("do", self._do_phase)
        workflow.add_node("check", self._check_phase)
        workflow.add_node("act", self._act_phase)
        workflow.add_node("complete", self._complete_phase)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.add_edge(START, "plan")
        
        # å®šä¹‰æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "plan",
            self._should_continue_from_plan,
            {
                "do": "do",
                "complete": "complete"
            }
        )
        
        workflow.add_conditional_edges(
            "do",
            self._should_continue_from_do,
            {
                "check": "check",
                "complete": "complete"
            }
        )
        
        workflow.add_conditional_edges(
            "check",
            self._should_continue_from_check,
            {
                "act": "act",
                "complete": "complete"
            }
        )
        
        workflow.add_conditional_edges(
            "act",
            self._should_continue_from_act,
            {
                "plan": "plan",
                "complete": "complete"
            }
        )
        
        workflow.add_edge("complete", END)
        
        # ç¼–è¯‘å›¾
        return workflow.compile(checkpointer=self.memory)
    
    async def _plan_phase(self, state: PDCAState) -> PDCAState:
        """è®¡åˆ’é˜¶æ®µ"""
        print(f"ğŸ“‹ PLANé˜¶æ®µ - å¾ªç¯ {state['cycle_count'] + 1}")
        
        plan_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®ç®¡ç†AIåŠ©æ‰‹ã€‚è¯·ä¸ºç»™å®šçš„å·¥ä½œä»»åŠ¡åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
{
    "goals": ["ç›®æ ‡1", "ç›®æ ‡2"],
    "steps": [
        {"step": 1, "action": "å…·ä½“è¡ŒåŠ¨", "expected_outcome": "é¢„æœŸç»“æœ", "timeline": "æ—¶é—´ä¼°è®¡"},
        {"step": 2, "action": "å…·ä½“è¡ŒåŠ¨", "expected_outcome": "é¢„æœŸç»“æœ", "timeline": "æ—¶é—´ä¼°è®¡"}
    ],
    "resources_needed": ["èµ„æº1", "èµ„æº2"],
    "success_criteria": ["æˆåŠŸæ ‡å‡†1", "æˆåŠŸæ ‡å‡†2"],
    "potential_risks": ["é£é™©1", "é£é™©2"]
}"""),
            ("user", f"ä»»åŠ¡æè¿°ï¼š{state['task_description']}\n\nä¹‹å‰çš„æ”¹è¿›è¡ŒåŠ¨ï¼š{state.get('improvement_actions', [])}")
        ])
        
        response = await self.llm.ainvoke(plan_prompt.format_messages())
        
        try:
            # è§£æJSONå“åº”
            plan_content = response.content.strip()
            if plan_content.startswith("```json"):
                plan_content = plan_content.replace("```json", "").replace("```", "").strip()
            
            plan = json.loads(plan_content)
        except json.JSONDecodeError:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œåˆ›å»ºåŸºæœ¬è®¡åˆ’
            plan = {
                "goals": ["å®ŒæˆæŒ‡å®šä»»åŠ¡"],
                "steps": [{"step": 1, "action": "å¼€å§‹æ‰§è¡Œä»»åŠ¡", "expected_outcome": "ä»»åŠ¡è¿›å±•", "timeline": "1å°æ—¶"}],
                "resources_needed": ["æ—¶é—´", "æ³¨æ„åŠ›"],
                "success_criteria": ["ä»»åŠ¡å®Œæˆ"],
                "potential_risks": ["æ—¶é—´ä¸è¶³"]
            }
        
        state["current_phase"] = "plan"
        state["plan"] = plan
        state["messages"].append(AIMessage(content=f"åˆ¶å®šäº†æ–°çš„æ‰§è¡Œè®¡åˆ’ï¼š\n{json.dumps(plan, ensure_ascii=False, indent=2)}"))
        
        return state
    
    async def _do_phase(self, state: PDCAState) -> PDCAState:
        """æ‰§è¡Œé˜¶æ®µ"""
        print(f"ğŸš€ DOé˜¶æ®µ - æ‰§è¡Œè®¡åˆ’")
        
        do_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡æ‰§è¡ŒAIåŠ©æ‰‹ã€‚è¯·æ ¹æ®åˆ¶å®šçš„è®¡åˆ’æ¨¡æ‹Ÿæ‰§è¡Œä»»åŠ¡ï¼Œå¹¶è®°å½•æ‰§è¡Œè¿‡ç¨‹ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
{
    "executed_steps": [
        {"step": 1, "action_taken": "å®é™…æ‰§è¡Œçš„è¡ŒåŠ¨", "result": "æ‰§è¡Œç»“æœ", "issues": "é‡åˆ°çš„é—®é¢˜"}
    ],
    "overall_progress": "æ•´ä½“è¿›åº¦ç™¾åˆ†æ¯”(0-100)",
    "challenges_encountered": ["æŒ‘æˆ˜1", "æŒ‘æˆ˜2"],
    "unexpected_outcomes": ["æ„å¤–ç»“æœ1", "æ„å¤–ç»“æœ2"]
}"""),
            ("user", f"è¯·æ‰§è¡Œä»¥ä¸‹è®¡åˆ’ï¼š\n{json.dumps(state['plan'], ensure_ascii=False, indent=2)}")
        ])
        
        response = await self.llm.ainvoke(do_prompt.format_messages())
        
        try:
            execution_content = response.content.strip()
            if execution_content.startswith("```json"):
                execution_content = execution_content.replace("```json", "").replace("```", "").strip()
            
            execution_result = json.loads(execution_content)
        except json.JSONDecodeError:
            execution_result = {
                "executed_steps": [{"step": 1, "action_taken": "æ‰§è¡Œäº†åŸºæœ¬ä»»åŠ¡", "result": "å–å¾—è¿›å±•", "issues": "æ— "}],
                "overall_progress": "50",
                "challenges_encountered": [],
                "unexpected_outcomes": []
            }
        
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        log_entry = f"[{datetime.now().strftime('%H:%M:%S')}] æ‰§è¡Œè¿›åº¦: {execution_result['overall_progress']}%"
        state["execution_log"].append(log_entry)
        
        state["current_phase"] = "do"
        state["messages"].append(AIMessage(content=f"æ‰§è¡Œç»“æœï¼š\n{json.dumps(execution_result, ensure_ascii=False, indent=2)}"))
        
        return state
    
    async def _check_phase(self, state: PDCAState) -> PDCAState:
        """æ£€æŸ¥é˜¶æ®µ"""
        print(f"ğŸ” CHECKé˜¶æ®µ - æ£€æŸ¥ç»“æœ")
        
        check_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªè´¨é‡æ£€æŸ¥AIåŠ©æ‰‹ã€‚è¯·è¯„ä¼°ä»»åŠ¡æ‰§è¡Œç»“æœï¼Œä¸åŸè®¡åˆ’è¿›è¡Œå¯¹æ¯”ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
{
    "goals_achieved": ["å·²å®ç°çš„ç›®æ ‡"],
    "goals_missed": ["æœªå®ç°çš„ç›®æ ‡"],
    "plan_vs_actual": {
        "planned_timeline": "è®¡åˆ’æ—¶é—´",
        "actual_timeline": "å®é™…æ—¶é—´",
        "planned_resources": "è®¡åˆ’èµ„æº",
        "actual_resources": "å®é™…èµ„æº"
    },
    "quality_score": 85,
    "areas_for_improvement": ["æ”¹è¿›ç‚¹1", "æ”¹è¿›ç‚¹2"],
    "lessons_learned": ["ç»éªŒ1", "ç»éªŒ2"],
    "next_cycle_recommendations": ["å»ºè®®1", "å»ºè®®2"]
}"""),
            ("user", f"åŸè®¡åˆ’ï¼š\n{json.dumps(state['plan'], ensure_ascii=False, indent=2)}\n\næ‰§è¡Œæ—¥å¿—ï¼š\n{chr(10).join(state['execution_log'])}")
        ])
        
        response = await self.llm.ainvoke(check_prompt.format_messages())
        
        try:
            check_content = response.content.strip()
            if check_content.startswith("```json"):
                check_content = check_content.replace("```json", "").replace("```", "").strip()
            
            check_results = json.loads(check_content)
        except json.JSONDecodeError:
            check_results = {
                "goals_achieved": ["éƒ¨åˆ†ç›®æ ‡å®Œæˆ"],
                "goals_missed": [],
                "quality_score": 70,
                "areas_for_improvement": ["æ•ˆç‡æå‡"],
                "lessons_learned": ["éœ€è¦æ›´å¥½çš„è®¡åˆ’"],
                "next_cycle_recommendations": ["ä¼˜åŒ–æµç¨‹"]
            }
        
        state["current_phase"] = "check"
        state["check_results"] = check_results
        state["messages"].append(AIMessage(content=f"æ£€æŸ¥ç»“æœï¼š\n{json.dumps(check_results, ensure_ascii=False, indent=2)}"))
        
        return state
    
    async def _act_phase(self, state: PDCAState) -> PDCAState:
        """è¡ŒåŠ¨é˜¶æ®µ"""
        print(f"âš¡ ACTé˜¶æ®µ - åˆ¶å®šæ”¹è¿›è¡ŒåŠ¨")
        
        act_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæŒç»­æ”¹è¿›AIåŠ©æ‰‹ã€‚åŸºäºæ£€æŸ¥ç»“æœï¼Œåˆ¶å®šå…·ä½“çš„æ”¹è¿›è¡ŒåŠ¨ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
{
    "improvement_actions": ["å…·ä½“æ”¹è¿›è¡ŒåŠ¨1", "å…·ä½“æ”¹è¿›è¡ŒåŠ¨2"],
    "process_changes": ["æµç¨‹æ”¹å˜1", "æµç¨‹æ”¹å˜2"],
    "resource_adjustments": ["èµ„æºè°ƒæ•´1", "èµ„æºè°ƒæ•´2"],
    "should_continue_cycle": true,
    "reason_to_continue": "ç»§ç»­çš„åŸå› ",
    "expected_improvements": ["é¢„æœŸæ”¹è¿›1", "é¢„æœŸæ”¹è¿›2"]
}"""),
            ("user", f"æ£€æŸ¥ç»“æœï¼š\n{json.dumps(state['check_results'], ensure_ascii=False, indent=2)}")
        ])
        
        response = await self.llm.ainvoke(act_prompt.format_messages())
        
        try:
            act_content = response.content.strip()
            if act_content.startswith("```json"):
                act_content = act_content.replace("```json", "").replace("```", "").strip()
            
            act_results = json.loads(act_content)
        except json.JSONDecodeError:
            act_results = {
                "improvement_actions": ["ä¼˜åŒ–æ‰§è¡Œæµç¨‹"],
                "process_changes": ["è°ƒæ•´æ—¶é—´å®‰æ’"],
                "resource_adjustments": ["å¢åŠ æ³¨æ„åŠ›æŠ•å…¥"],
                "should_continue_cycle": False,
                "reason_to_continue": "ä»»åŠ¡åŸºæœ¬å®Œæˆ",
                "expected_improvements": ["æ•ˆç‡æå‡"]
            }
        
        state["current_phase"] = "act"
        state["improvement_actions"] = act_results.get("improvement_actions", [])
        state["cycle_count"] += 1
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­å¾ªç¯
        if (act_results.get("should_continue_cycle", False) and 
            state["cycle_count"] < 3 and  # æœ€å¤š3ä¸ªå¾ªç¯
            state["check_results"].get("quality_score", 0) < 90):
            state["is_complete"] = False
        else:
            state["is_complete"] = True
        
        state["messages"].append(AIMessage(content=f"æ”¹è¿›è¡ŒåŠ¨ï¼š\n{json.dumps(act_results, ensure_ascii=False, indent=2)}"))
        
        return state
    
    async def _complete_phase(self, state: PDCAState) -> PDCAState:
        """å®Œæˆé˜¶æ®µ"""
        print(f"âœ… COMPLETEé˜¶æ®µ - ä»»åŠ¡å®Œæˆ")
        
        summary = {
            "task": state["task_description"],
            "total_cycles": state["cycle_count"],
            "final_quality_score": state["check_results"].get("quality_score", 0),
            "lessons_learned": state["check_results"].get("lessons_learned", []),
            "improvements_made": state["improvement_actions"]
        }
        
        state["current_phase"] = "complete"
        state["messages"].append(AIMessage(content=f"ğŸ‰ ä»»åŠ¡å®Œæˆæ€»ç»“ï¼š\n{json.dumps(summary, ensure_ascii=False, indent=2)}"))
        
        return state
    
    def _should_continue_from_plan(self, state: PDCAState) -> str:
        """ä»è®¡åˆ’é˜¶æ®µçš„æ¡ä»¶åˆ¤æ–­"""
        return "do" if state.get("plan") else "complete"
    
    def _should_continue_from_do(self, state: PDCAState) -> str:
        """ä»æ‰§è¡Œé˜¶æ®µçš„æ¡ä»¶åˆ¤æ–­"""
        return "check" if state.get("execution_log") else "complete"
    
    def _should_continue_from_check(self, state: PDCAState) -> str:
        """ä»æ£€æŸ¥é˜¶æ®µçš„æ¡ä»¶åˆ¤æ–­"""
        return "act" if state.get("check_results") else "complete"
    
    def _should_continue_from_act(self, state: PDCAState) -> str:
        """ä»è¡ŒåŠ¨é˜¶æ®µçš„æ¡ä»¶åˆ¤æ–­"""
        if state.get("is_complete", True):
            return "complete"
        else:
            return "plan"  # å¼€å§‹æ–°çš„PDCAå¾ªç¯
    
    async def process_task(self, task_description: str) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œä»»åŠ¡"""
        print(f"ğŸ¯ å¼€å§‹å¤„ç†ä»»åŠ¡: {task_description}")
        print("=" * 50)
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = PDCAState(
            task_description=task_description,
            current_phase="",
            plan={},
            execution_log=[],
            check_results={},
            improvement_actions=[],
            cycle_count=0,
            is_complete=False,
            messages=[HumanMessage(content=task_description)]
        )
        
        # åˆ›å»ºçº¿ç¨‹é…ç½®
        config = {"configurable": {"thread_id": f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}"}}
        
        # è¿è¡Œå›¾
        result = await self.graph.ainvoke(initial_state, config)
        
        print("=" * 50)
        print("ğŸ ä»»åŠ¡å¤„ç†å®Œæˆ!")
        
        return result

async def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    print("ğŸ¤– LangGraph PDCAå¾ªç¯Agent Demo")
    print("åŸºäºGPT-4oçš„å·¥ä½œä»»åŠ¡å¤„ç†ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆ›å»ºagent
    agent = PDCAAgent()
    
    # ç¤ºä¾‹ä»»åŠ¡
    tasks = [
        "å¼€å‘ä¸€ä¸ªç”¨æˆ·ç™»å½•åŠŸèƒ½çš„Webåº”ç”¨",
        "å‡†å¤‡ä¸‹å‘¨çš„é¡¹ç›®æ±‡æŠ¥æ¼”ç¤º",
        "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"
    ]
    
    for i, task in enumerate(tasks, 1):
        print(f"\nğŸš€ ç¤ºä¾‹ä»»åŠ¡ {i}: {task}")
        print("-" * 40)
        
        try:
            result = await agent.process_task(task)
            
            # æ‰“å°æœ€ç»ˆç»“æœæ‘˜è¦
            print(f"\nğŸ“Š ä»»åŠ¡å®Œæˆæ‘˜è¦:")
            print(f"   â€¢ ä»»åŠ¡: {result['task_description']}")
            print(f"   â€¢ PDCAå¾ªç¯æ¬¡æ•°: {result['cycle_count']}")
            print(f"   â€¢ æœ€ç»ˆé˜¶æ®µ: {result['current_phase']}")
            print(f"   â€¢ è´¨é‡è¯„åˆ†: {result['check_results'].get('quality_score', 'N/A')}")
            print(f"   â€¢ æ”¹è¿›è¡ŒåŠ¨æ•°é‡: {len(result.get('improvement_actions', []))}")
            
        except Exception as e:
            print(f"âŒ å¤„ç†ä»»åŠ¡æ—¶å‡ºé”™: {e}")
        
        print("\n" + "="*60)
        
        # æš‚åœä¸€ä¸‹ï¼Œé¿å…APIè°ƒç”¨è¿‡å¿«
        await asyncio.sleep(2)

if __name__ == "__main__":
    asyncio.run(main()) 