#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
GPT-4oç®€åŒ–é€‰æ‹©æµ‹è¯•è„šæœ¬
"""

import os
import json
import csv
import sys
import asyncio
import traceback
from PIL import Image

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from util.image_element_analyzer import ImageElementAnalyzer
from util.config import get_config

from util.adb_mcp_driver import (
    test_mcp_connection,
    get_mcp_tools_list,
    execute_mcp_tool,
    load_client_config
)




def send_llm_message(message: str, max_tokens: int = 100, temperature: float = 0.1) -> dict:
    """å‘é€LLMæ¶ˆæ¯çš„å…¬å…±æ–¹æ³•
    
    Args:
        message: è¦å‘é€çš„æ¶ˆæ¯å†…å®¹
        max_tokens: æœ€å¤§ä»¤ç‰Œæ•°
        temperature: æ¸©åº¦å‚æ•°
        
    Returns:
        dict: åŒ…å«successã€contentã€errorçš„ç»“æœå­—å…¸
    """
    try:
        from openai import OpenAI
        
        # ç›´æ¥ä»é…ç½®æ–‡ä»¶è¯»å–
        with open("config.json", 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        openai_config = config.get("openai", {})
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAI(
            api_key=openai_config["api_key"],
            base_url=openai_config["base_url"]
        )
        
        print(f"ğŸ¤– æ­£åœ¨å‘é€æ¶ˆæ¯ç»™LLM...")
        response = client.chat.completions.create(
            model=openai_config["model"],
            messages=[{"role": "user", "content": message}],
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        result = response.choices[0].message.content.strip()
        print(f"âœ… LLMå“åº”æˆåŠŸï¼")
        
        return {
            "success": True,
            "content": result,
            "error": None
        }
        
    except Exception as e:
        print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
        return {
            "success": False,
            "content": None,
            "error": str(e)
        }

def test_api():
    """æµ‹è¯•APIè¿æ¥"""
    result = send_llm_message("è¯·å›å¤'æµ‹è¯•æˆåŠŸ'", max_tokens=10)
    
    if result["success"]:
        print(f"âœ… APIè¿æ¥æˆåŠŸï¼å“åº”: {result['content']}")
        return True
    else:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {result['error']}")
        return False

def test_main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ GPT-4o APIè¿æ¥æµ‹è¯•")
    print("=" * 30)
    
    if test_api():
        print("âœ… å¯ä»¥å¼€å§‹è¿›è¡ŒçœŸå®çš„é€‰æ‹©æµ‹è¯•")
    else:
        print("âŒ éœ€è¦å…ˆè§£å†³APIè¿æ¥é—®é¢˜")

def main():

    # åˆå§‹åŒ–system message
    system_message = """
    ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡é€‰æ‹©åŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡ï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä»»åŠ¡ã€‚
    """
    #å‘é€æ¶ˆæ¯ç»™LLM
    result = send_llm_message(system_message)
    print(result)

    # å‘é€æ¶ˆæ¯ç»™LLM
    # å‘½ä»¤è¡Œæ¥æ”¶ä¸€ä¸ªä»»åŠ¡è¾“å…¥
    task = input("è¯·è¾“å…¥ä»»åŠ¡: ")
    

    # ç¼–å†™ä»»åŠ¡æç¤ºè¯ï¼Œå¹¶å‘é€ç»™LLM
    prompt = """
    ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡é€‰æ‹©åŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡ï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä»»åŠ¡ã€‚
    ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡æ˜¯ï¼š{task}
    è¯·æ ¹æ®ä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„ä»»åŠ¡ã€‚ä½ å¯ä»¥æ§åˆ¶è®¾å¤‡ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œæˆªå›¾ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œæ–‡å­—è¾“å…¥ã€‚
    è¯·æ ¹æ®ä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„ä»»åŠ¡ã€‚
            ADB MCP Demo å‘½ä»¤å¸®åŠ©:

        åŸºç¡€å‘½ä»¤:
        connect              - æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥
        tools                - è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        help                 - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

        å±å¹•æ“ä½œ:
        wake                 - å”¤é†’å±å¹•
        screenshot [c]       - æˆªå›¾ (c=å‹ç¼©)
        click <x> <y>        - ç‚¹å‡»å±å¹•åæ ‡
        swipe <x1> <y1> <x2> <y2> [duration] - æ»‘åŠ¨å±å¹•
        home                 - å›åˆ°ä¸»å±å¹•
        back                 - æŒ‰è¿”å›é”®

        æ–‡æœ¬è¾“å…¥:
        input <text>         - è¾“å…¥æ–‡æœ¬

        ç¤ºä¾‹:
        click 100 200        - ç‚¹å‡»åæ ‡(100, 200)
        input hello world    - è¾“å…¥"hello world"
        screenshot c         - å‹ç¼©æˆªå›¾
        swipe 100 500 100 200 1000 - ä»(100,500)æ»‘åŠ¨åˆ°(100,200)ï¼ŒæŒç»­1ç§’

        ä½ éœ€è¦è¿”å›ä¸€ä¸ªlistæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªæ“ä½œæ­¥éª¤åŒ…å«ä»¥ä¸‹å­—æ®µï¼š  
    """
    llm_message = {
        "role": "user",
        "content": task
    }

    # è°ƒç”¨LLMè¿›è¡Œé€‰æ‹©
    result = send_llm_message(llm_message)
    

if __name__ == "__main__":
    main() 